<!DOCTYPE html>
<html>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-83146017-1', 'auto');
  ga('send', 'pageview');

</script>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="ROCm, a New Era in Open GPU Computing : Platform for GPU-Enabled HPC and Ultrascale Computing ">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>ROCm, a New Era in Open GPU Computing</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/RadeonOpenCompute">View on GitHub</a>
          <img class="wrap" src="images/ROCm_Logo_128.png" alt="ROCm_Logo" />
          <h2 id="project_title">ROCm, a New Era in Open GPU Computing</h2>
          <h3 id="project_tagline">Platform for GPU-Enabled HPC and Ultrascale Computing </h3>

       
      
    </div>

<div>

<ul>
  <div id="nav">
      <div id="nbar">
        <ul>
          <li><a href="index.html">Overview</a></li>
          <li><a href="install.html">Install</a></li>
          <li><a href="languages.html">Languages</a></li>
          <li><a href="documentation.html">Documentation</a></li>
          <li><a href="packages.html">ROCm Solutions </a></li>
          <li><a href="tutorials.html">Tutorials</a></li>
          <li><a href="hardware.html">ROCm Hardware</a></li>
          <li><a href="blog.html">ROCm BLOG</a></li>
        </ul>
      </div>
      </div>
</ul>
</nav>
    </div>
 </header>
       <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
<h1 id="ROCm-Blog">ROCm Blog Roll</h1>

<h3>ROCm Device Libraries Now Available!</h3>

<p>We are pleased to announce <a href="https://github.com/RadeonOpenCompute/ROCm-Device-Libs">fully open-source bitcode device libraries</a> for the ROCm platform.</p>

<p>The following libraries are available:</p>
<ul>
<li> Open Compute Math Library (OCML)&mdash;contains 250+ optimized math functions for single, double and half precision. See the <a href="https://github.com/RadeonOpenCompute/ROCm-Device-Libs/blob/master/doc/OCML.md#supported-functions">OCML documentation</a>
for a list of currently supported functions.</li>

<li> Open Compute Kernel Library (OCKL)&mdash;contains many useful functions, including work-item/workgroup functions,
integer optimization operations and wavefront reduce algorithms. It also serves as a foundation for the built-in library of the OpenCL-enabled compiler.</li>

<li> Compiler built-in library to support OpenCL.</li>

<li> Compler built-in library for the HC mode of the <a href="http://gpuopen.com/compute-product/hcc-heterogeneous-compute-compiler/">Heterogeneous Compute Compiler (HCC)</a>.</li>

<li> OCLC libraries&mdash;enable fine-grain control over library modes (such as relaxed math).</li>

<li> IRIF&mdash;interface library to AMD GPU back end.</li>
</ul>

<p>The libraries are intended for language and run-time implementors. They work with the open-source AMD GPU LLVM back end on GCN architectures and link to user bitcode through the LLVM linker before code generation.</p>

<p>ROCm-Device-Libs is currently under development, so we expect many improvements. As always, contributions and other feedback are welcome.</p>




<h3>Quick Way To Access ROCm GPU Performance Counters via CodeXL</h3>
<p>You can get the list of available counters by running the following command:</p>
<ul>
<li>./CodeXLGpuProfiler --list</li>
</ul>
<p>To save the counter list to a file, use</p>
<ul>
<li>./CodeXLGpuProfiler --list --outputfile counters.txt</li>
</ul>
<p>Next, specify the set of counters using the following command:</p>
<ul>
<li>./CodeXLGpuProfiler --hsapmc --counterfile</li>
</ul>
<p>"counters.txt" should list one counter name per line.</p>


<h3>HCC Getting a Little Richer in Low-level Optimizations</h3>
<ul>
<li> 24-bit integer multiply and multiply-add (__mul24 and __mad24)</li>
<li>Intrinsics for ds_permute and ds_bpermute (__amdgcn_ds_permute and __amdgcn_ds_bpermute)</li>
<li>Intrinsics for ds_swizzle (__amdgcn_ds_swizzle)</li>
<li>Intrinsics for wave shift and rotate by one thread (__amdgcn_wave_*)</li>
<li>Intrinsic for move dpp (__amdgcn_move_dpp)</li>
</ul>
<p>Example of HCC Fuctions</p>
<ul>
<li>unsigned int 	hc::__activelaneid_u32 () __HC__</li>
 	<ul><li>Get the number of earlier (in flattened work item order) active work-items in the same wavefront. </li></ul>
 
<li>uint64_t 	hc::__activelanemask_v4_b64_b1 (unsigned int input) __HC__</li>
 	<ul><li>Return a bit mask showing which active work items in the wavefront have a nonzero input. </li></ul>
 
<li>unsigned int 	hc::__activelanecount_u32_b1 (unsigned int input) __HC__</li>
 	<ul><li>Count the number of active work items in the current wavefront that have a nonzero input.</li></ul>
 
<li>unsigned int 	hc::__activelanepermute_b32 (unsigned int src, unsigned int laneId, unsigned int identity, unsigned int useIdentity) __HC__</li>
 	<ul><li>Permute the active work items in the wavefront. </li></ul>
 
<li>int 	hc::__any (int predicate) __HC__</li>
 	<ul><li>Evaluate the predicate for all active work items in the wavefront and return a nonzero value if and only if the predicate evaluates to a nonzero value for all of them. </li></ul>
 
<li>int 	hc::__all (int predicate) __HC__</li>
 	<ul><li>Evaluate predicate for all active work items in the wavefront and return a nonzero value if and only if the predicate evaluates to a nonzero value for any one of them.</li></ul> 
 
<li>uint64_t 	hc::__ballot (int predicate) __HC__</li>
 	<ul><li>Evaluate predicate for all active work items in the wavefront and return an integer whose Nth bit is set if and only if the predicate evaluates to a nonzero value for the Nth work item of the wavefront and the Nth work item is active. </li></ul>
 
<li>unsigned int 	hc::__shfl_xor (unsigned int var, int laneMask, int width=__HSA_WAVEFRONT_SIZE__) __HC__ </li>

</ul>
<a href="http://scchan.github.io/hcc/hc_8hpp.html">Find out more about these HCC fuctions.</a>
<h3>It’s Time to ROC</h3>
<iframe width="560" height="315" src="https://www.youtube.com/embed/dnKDFci2x2Q" frameborder="0" allowfullscreen></iframe>
<p>HPC User Forum in Tucson; Gregory Stoner from AMD presents <q>It's Time to ROC.</q></p>
<h3>Rolling Out HIP Version 0.86 </h3>
The team just released an update to <a href="https://github.com/GPUOpen-ProfessionalCompute-Tools/HIP" target="_blank">HIP</a> in version 0.86 that includes multiple improvements to the capabilities and tools. Also, we added several more HIP ports and <a href="https://github.com/GPUOpen-ProfessionalCompute-Tools/HIP-Examples">examples</a>.

If you’re just getting started, HIP (Heterogeneous-Computing Interface for Portability) is a portable C++ run time and kernel language for GPUs. It includes tools to <q>hipify</q> Cuda code into the portable C++ language.
<h4>HIP 0.86 Release Notes</h4>
<em>Release: 0.86.00</em></br>
<em>Date: 2016.06.06</em>
<p></p>
<ul>
 	<li>Add clang-hipify&mdash;a Clang-based hipify tool that improves parsing of source code and automates
creation of hipLaunchParm variable.</li>
 	<li>Implement memory register/unregister commands (hipHostRegister, hipHostUnregister)</li>
 	<li>Add cross-linking support between G++ and HCC, in particular for interfaces that use
standard C++ libraries (i.e., std::vectors, std::strings). HIPCC now uses libstdc++ by default on the HCC
compilation path.</li>
 	<li>Include more samples, such as gpu-burn, <a href="https://github.com/vetter/shoc/pull/50" target="_blank">SHOC</a>, nbody and rtm. See <a href="https://github.com/GPUOpen-ProfessionalCompute-Tools/HIP-Examples" target="_blank">HIP-Examples</a>.</li>
</ul>
<h4>Info on Previous 0.84 Release</h4>
<em>Release: 0.84.01</em></br>
<em>Date: 2016.04.25</em>
<p></p>
<ul>
<li> Refactor HIP make and install system.</li>
<li> Move to CMake. Refer to the installation section in README.md for details.</li>
<li> Split source into multiple modular .cpp and .h files.</li>
<li> Create static library and link.</li>
<li> Set HIP_PATH to install.</li>
<li> Make hipDevice and hipStream thread-safe.</li>
<li> Preferred hipStream usage still involves creating new streams for each new thread, but it works even if you don’t.</li>
<li> Improve automatic platform detection: if an AMD GPU is installed and the driver detects it, default HIP_PLATFORM to hcc.</li>
<li> HIP_TRACE_API now prints arguments to the HIP function (in addition to the function name).</li>
<li> Deprecate hipDeviceGetProp (replace with hipGetDeviceProp).</li>
<li> Deprecate hipMallocHost (replace with hipHostMalloc).</li>
<li> Deprecate hipFreeHost (replace with hipHostFree).</li>
<li> The Mixbench benchmark tool for measuring operational intensity now has a HIP target, in addition to Cuda and OpenCL. Let the comparisons begin! See the <a href="https://github.com/ekondis/mixbench" target="_blank">Mixbench</a> GitHub site for more information.</li>
</ul>

<h4>Related Resources</h4>
<ul>
 	<li><a href="http://gpuopen.com/tag/hip/">Technical blogs</a></li>
 	<li><a href="https://github.com/GPUOpen-ProfessionalCompute-Tools/HIP" target="_blank">HIP GitHub repository</a></li>
</ul>

<!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p> © 2016 AMD Corporation <a href="legal.html">Disclaimer and Legal Information</a> </p> 
      </footer>
    </div>
    
  </body>
</html>
